{
  "timestamp": "2026-02-18T00:16:08",
  "proxy_url": "http://localhost:4000",
  "total": 17,
  "passed": 11,
  "failed": 0,
  "fallbacks": 6,
  "tier_breakdown": {
    "T1-FREE": {
      "total": 3,
      "passed": 3,
      "failed": 0
    },
    "T2-COMPLEX": {
      "total": 1,
      "passed": 1,
      "failed": 0
    },
    "T3-ARCHITECT": {
      "total": 1,
      "passed": 1,
      "failed": 0
    },
    "T4-PAID": {
      "total": 3,
      "passed": 3,
      "failed": 0
    },
    "FALLBACK": {
      "total": 5,
      "passed": 5,
      "failed": 0
    },
    "CONCURRENT": {
      "total": 4,
      "passed": 4,
      "failed": 0
    }
  },
  "results": [
    {
      "model": "minimax-free",
      "tier": "T1-FREE",
      "test_type": "direct",
      "status": "FALLBACK",
      "latency_ms": 36189,
      "response_text": "What's next?",
      "model_used": "llama-3.1-8b-instant",
      "error": "",
      "http_status": 200
    },
    {
      "model": "glm4-free",
      "tier": "T1-FREE",
      "test_type": "direct",
      "status": "FALLBACK",
      "latency_ms": 37648,
      "response_text": "What's next?",
      "model_used": "llama-3.1-8b-instant",
      "error": "",
      "http_status": 200
    },
    {
      "model": "gemma-free",
      "tier": "T1-FREE",
      "test_type": "direct",
      "status": "FALLBACK",
      "latency_ms": 37253,
      "response_text": "What's next?",
      "model_used": "llama-3.1-8b-instant",
      "error": "",
      "http_status": 200
    },
    {
      "model": "gemini-flash",
      "tier": "T2-COMPLEX",
      "test_type": "direct",
      "status": "FALLBACK",
      "latency_ms": 32378,
      "response_text": "What's next?",
      "model_used": "llama-3.1-8b-instant",
      "error": "",
      "http_status": 200
    },
    {
      "model": "gemini-pro",
      "tier": "T3-ARCHITECT",
      "test_type": "direct",
      "status": "FALLBACK",
      "latency_ms": 28955,
      "response_text": "What's next?",
      "model_used": "llama-3.1-8b-instant",
      "error": "",
      "http_status": 200
    },
    {
      "model": "groq-llama-70b",
      "tier": "T4-PAID",
      "test_type": "direct",
      "status": "PASS",
      "latency_ms": 2222,
      "response_text": "OK",
      "model_used": "llama-3.3-70b-versatile",
      "error": "",
      "http_status": 200
    },
    {
      "model": "groq-llama-8b",
      "tier": "T4-PAID",
      "test_type": "direct",
      "status": "PASS",
      "latency_ms": 2248,
      "response_text": "What's next?",
      "model_used": "llama-3.1-8b-instant",
      "error": "",
      "http_status": 200
    },
    {
      "model": "gpt-4o-mini",
      "tier": "T4-PAID",
      "test_type": "direct",
      "status": "FALLBACK",
      "latency_ms": 10941,
      "response_text": "OK",
      "model_used": "llama-3.3-70b-versatile",
      "error": "",
      "http_status": 200
    },
    {
      "model": "minimax-free",
      "tier": "FALLBACK",
      "test_type": "fallback",
      "status": "PASS",
      "latency_ms": 36667,
      "response_text": "What's next?",
      "model_used": "llama-3.1-8b-instant",
      "error": "",
      "http_status": 200
    },
    {
      "model": "glm4-free",
      "tier": "FALLBACK",
      "test_type": "fallback",
      "status": "PASS",
      "latency_ms": 36104,
      "response_text": "What's next?",
      "model_used": "llama-3.1-8b-instant",
      "error": "",
      "http_status": 200
    },
    {
      "model": "gemini-flash",
      "tier": "FALLBACK",
      "test_type": "fallback",
      "status": "PASS",
      "latency_ms": 33647,
      "response_text": "What's next?",
      "model_used": "llama-3.1-8b-instant",
      "error": "",
      "http_status": 200
    },
    {
      "model": "gemini-pro",
      "tier": "FALLBACK",
      "test_type": "fallback",
      "status": "PASS",
      "latency_ms": 32413,
      "response_text": "What's next?",
      "model_used": "llama-3.1-8b-instant",
      "error": "",
      "http_status": 200
    },
    {
      "model": "groq-llama-70b",
      "tier": "FALLBACK",
      "test_type": "fallback",
      "status": "PASS",
      "latency_ms": 2312,
      "response_text": "OK",
      "model_used": "llama-3.3-70b-versatile",
      "error": "",
      "http_status": 200
    },
    {
      "model": "groq-llama-8b",
      "tier": "CONCURRENT",
      "test_type": "concurrent",
      "status": "PASS",
      "latency_ms": 2236,
      "response_text": "What's next?",
      "model_used": "llama-3.1-8b-instant",
      "error": "",
      "http_status": 200
    },
    {
      "model": "groq-llama-8b",
      "tier": "CONCURRENT",
      "test_type": "concurrent",
      "status": "PASS",
      "latency_ms": 2240,
      "response_text": "What's next?",
      "model_used": "llama-3.1-8b-instant",
      "error": "",
      "http_status": 200
    },
    {
      "model": "groq-llama-8b",
      "tier": "CONCURRENT",
      "test_type": "concurrent",
      "status": "PASS",
      "latency_ms": 2355,
      "response_text": "What's next?",
      "model_used": "llama-3.1-8b-instant",
      "error": "",
      "http_status": 200
    },
    {
      "model": "groq-llama-8b",
      "tier": "CONCURRENT",
      "test_type": "concurrent",
      "status": "PASS",
      "latency_ms": 2361,
      "response_text": "What's next?",
      "model_used": "llama-3.1-8b-instant",
      "error": "",
      "http_status": 200
    }
  ]
}